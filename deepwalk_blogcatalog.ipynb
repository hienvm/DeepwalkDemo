{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 8517227,
          "sourceType": "datasetVersion",
          "datasetId": 5085144
        }
      ],
      "dockerImageVersionId": 30698,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "DeepWalk BlogCatalog",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hienvm/DeepwalkDemo/blob/main/deepwalk_blogcatalog.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'blogcatalog:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F5085144%2F8517227%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240527%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240527T180050Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D72f11efe7ffb8655c2897ecf4aeb8eb7d9f8abfb27e96fababe385fdd1cc0e3c62ea52ec338bf4b826f00935ee3d92c9f34ec08720639f9ae76ff98b2348566c27afef12b84435fe0bebc77b95fda8e731ccf0b29d0e32bbd9e66b6a4c113c9a39ec5936df1665098b6988ec7900bdffdbf881c2dd388aa9d002cfdad4a8d0c7a31ef02595e1019e3c6982298359fd135ef0d8ba3b7093cc673815a26ac82043935c29bc3c8ef1a0ddb79d5832fc94fb94ef3577114bcab65c48ed4c32f2b2102989f5992ef325030f9eb8bc736e1916dde54120e35dfb1e228c3049bdb1ea30e4fb3cb0cdac8f6ca9e3165574bd313f9a0d07f47ef67ac8a9105f0b582e43f7'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "aYu_osmSNgNU"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deepwalk Implementation cho BlogCatalog\n"
      ],
      "metadata": {
        "id": "mDFPDVRLNgNZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "from torch import tensor, Tensor\n",
        "from sklearn.manifold import TSNE\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import numpy.random as random\n",
        "import torch.multiprocessing as mp"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T16:30:18.732859Z",
          "iopub.execute_input": "2024-05-27T16:30:18.733205Z",
          "iopub.status.idle": "2024-05-27T16:30:23.359406Z",
          "shell.execute_reply.started": "2024-05-27T16:30:18.733179Z",
          "shell.execute_reply": "2024-05-27T16:30:23.356714Z"
        },
        "trusted": true,
        "id": "B4Wndip1NgNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Các Hyperparameter\n"
      ],
      "metadata": {
        "id": "wvQZ7cMxNgNc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_SIZE = 64\n",
        "WALK_LENGTH = 20\n",
        "WALKS_PER_VERTEX = 10\n",
        "WINDOW_SIZE = 5\n",
        "START_LEARNING_RATE = 0.025\n",
        "END_LEARNING_RATE = 0.005\n",
        "# Tiền xử lý 1D embedding\n",
        "PREPROCESS_WALKS_PER_VERTEX = 10\n",
        "# Dùng cho TSNE\n",
        "PERPLEXITY = 30"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T16:30:23.360237Z",
          "iopub.status.idle": "2024-05-27T16:30:23.360589Z",
          "shell.execute_reply.started": "2024-05-27T16:30:23.360418Z",
          "shell.execute_reply": "2024-05-27T16:30:23.360433Z"
        },
        "trusted": true,
        "id": "1ADo1_SQNgNc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "device và worker_threads\n"
      ],
      "metadata": {
        "id": "9zNIi8_HNgNd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "WORKER_THREADS = torch.cuda.device_count(\n",
        ") if torch.cuda.is_available() else mp.cpu_count()\n",
        "WORKER_THREADS = 1\n",
        "CHUNK_SIZE = 4\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "print(WORKER_THREADS)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T16:30:23.362627Z",
          "iopub.status.idle": "2024-05-27T16:30:23.363605Z",
          "shell.execute_reply.started": "2024-05-27T16:30:23.363341Z",
          "shell.execute_reply": "2024-05-27T16:30:23.363363Z"
        },
        "trusted": true,
        "id": "iqiYl5IlNgNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load dataset\n"
      ],
      "metadata": {
        "id": "ooSZyI8QNgNe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/kaggle/input/blogcatalog/edges.csv\", header=None).sub(1)\n",
        "g: nx.Graph = nx.from_pandas_edgelist(df, source=0, target=1)\n",
        "\n",
        "df = pd.read_csv(\"/kaggle/input/blogcatalog/group-edges.csv\", header=None).sub(1)\n",
        "nx.set_node_attributes(g, {row[0]: row[1] for row in df.iterrows()}, name=\"group\")\n",
        "vertices = tuple(sorted(g))\n",
        "adj_lists = [tuple(g.neighbors(v)) for v in vertices]\n",
        "V = len(g)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T16:30:23.364917Z",
          "iopub.status.idle": "2024-05-27T16:30:23.365883Z",
          "shell.execute_reply.started": "2024-05-27T16:30:23.365583Z",
          "shell.execute_reply": "2024-05-27T16:30:23.365605Z"
        },
        "trusted": true,
        "id": "gmYFLb33NgNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "def similarity(u: Tensor, v: Tensor) -> Tensor:\n",
        "    # có thể dùng khoảng cách euclid cho 1D\n",
        "    # if u.dim() == 0:\n",
        "    #     return u.subtract(v).abs()\n",
        "    return u.dot(v)\n",
        "\n",
        "def random_walk(v, adj_lists, walk_len):\n",
        "    '''deepwalk'''\n",
        "    # walk bắt đầu từ v\n",
        "    walk = [v]\n",
        "    for i in range(walk_len - 1):\n",
        "        # chọn đỉnh kề ngẫu nhiên\n",
        "        next_node = random.choice(adj_lists[v])\n",
        "        # thêm đỉnh kề vào walk\n",
        "        walk.append(next_node)\n",
        "        # nhảy tới đỉnh kề\n",
        "        v = next_node\n",
        "    return walk\n",
        "\n",
        "class DeepwalkModel(nn.Module):\n",
        "    def __init__(self, V: int, emb_sz: int, leaf_pos: list) -> None:\n",
        "        super(DeepwalkModel, self).__init__()\n",
        "        # Hidden layer biểu diễn vector cho đỉnh\n",
        "        self.embedding_layer = nn.Embedding(\n",
        "            num_embeddings=V, embedding_dim=emb_sz\n",
        "        )\n",
        "\n",
        "        # Biểu diễn T bằng complete binary tree đếm từ 0\n",
        "        # Luôn biểu diễn được T sao cho số lá tầng cuối = chẵn\n",
        "        # <=> số nút trong = số nút lá (tức V) - 1\n",
        "        self.inner_nodes_cnt = V - 1\n",
        "        # Output layer (các nút trong của T) cho hierarchical softmax\n",
        "        self.hsoftmax_layer = nn.Parameter(\n",
        "            torch.rand((self.inner_nodes_cnt, emb_sz))\n",
        "        )\n",
        "\n",
        "        # thứ tự lá\n",
        "        self.leaf_pos = leaf_pos\n",
        "\n",
        "    def forward(self, u: int, v: int):\n",
        "        \"\"\"Đoán Pr(u | v_emb), trả về loss function\"\"\"\n",
        "        loss = tensor(0.0)\n",
        "\n",
        "        # Lấy ra biểu diễn vector của v\n",
        "        v_emb = self.embedding_layer(tensor(v))\n",
        "\n",
        "        # Tính nút lá ứng với u trong cây nhị phân T\n",
        "        node = self.inner_nodes_cnt + self.leaf_pos[u]\n",
        "\n",
        "        while node:\n",
        "            # Kiểm tra nút hiện tại là con trái hay phải\n",
        "            isLeftChild = node & 1\n",
        "\n",
        "            # Nhảy lên nút cha\n",
        "            if isLeftChild:\n",
        "                node >>= 1\n",
        "            else:\n",
        "                node = (node - 1) >> 1\n",
        "\n",
        "            # Lấy ra biểu diễn vector của nút trong\n",
        "            node_emb = self.hsoftmax_layer[tensor(node)]\n",
        "\n",
        "            # cập nhật loss function trên đường đi tới gốc\n",
        "            if isLeftChild:\n",
        "                loss -= similarity(node_emb, v_emb).sigmoid().log()\n",
        "            else:\n",
        "                loss -= (\n",
        "                    tensor(1.0)\n",
        "                    - similarity(node_emb, v_emb).sigmoid()\n",
        "                ).log()\n",
        "        return loss\n",
        "\n",
        "\n",
        "def train_deepwalk(\n",
        "    model: nn.Module,\n",
        "    start_lr: float,\n",
        "    end_lr: float,\n",
        "    vertices: list,\n",
        "    adj_lists: list[list],\n",
        "    loss_records: list,\n",
        "    walk_len: int,\n",
        "    walks_per_vertex: int,\n",
        "    window_sz: int,\n",
        "    worker_threads: int,\n",
        "    chunk_sz: int,\n",
        "):\n",
        "    lr_step = (start_lr - end_lr) / walks_per_vertex\n",
        "    for i in tqdm(range(walks_per_vertex)):\n",
        "        epoch_loss = 0.0\n",
        "        cnt = 0\n",
        "        random.shuffle(vertices)\n",
        "        if worker_threads > 1:\n",
        "            with mp.Pool() as pool:\n",
        "                # sinh ra corpus và chia thành một batch cho mỗi walk từ một đỉnh nguồn\n",
        "                batches = [\n",
        "                    (\n",
        "                        random_walk(v, adj_lists, walk_len),\n",
        "                        window_sz,\n",
        "                        start_lr,\n",
        "                        model,\n",
        "                    ) for v in vertices\n",
        "                ]\n",
        "                # huấn luyện skipgram\n",
        "                results = pool.starmap(\n",
        "                    func=skip_gram_deepwalk,\n",
        "                    iterable=batches,\n",
        "                    chunksize=chunk_sz,\n",
        "                )\n",
        "            for (running_loss, running_cnt) in results:\n",
        "                # Ghi nhận lại hàm mất mát\n",
        "                epoch_loss += running_loss\n",
        "                cnt += running_cnt\n",
        "        else:\n",
        "            for src in vertices:\n",
        "                # lấy ra đường đi ngẫu nhiên\n",
        "                walk = random_walk(src, adj_lists, walk_len)\n",
        "                # huấn luyện skipgram\n",
        "                (running_loss, running_cnt) = skip_gram_deepwalk(\n",
        "                    walk=walk,\n",
        "                    window_sz=window_sz,\n",
        "                    lr=start_lr,\n",
        "                    model=model\n",
        "                )\n",
        "                # Ghi nhận lại hàm mất mát\n",
        "                epoch_loss += running_loss\n",
        "                cnt += running_cnt\n",
        "\n",
        "        # tính trung bình hàm mất mát cho lần chạy\n",
        "        loss_records.append(epoch_loss / cnt)\n",
        "\n",
        "        # Giảm tuyến tính tỉ lệ học\n",
        "        start_lr -= lr_step\n",
        "\n",
        "\n",
        "def skip_gram_deepwalk(walk: list, window_sz: int, lr: float, model: nn.Module):\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "    running_loss = 0.0\n",
        "    cnt = 0\n",
        "    # soft window\n",
        "    w = random.randint(1, window_sz)\n",
        "    for j, v in enumerate(walk):\n",
        "        window = walk[j - w: j] + walk[j + 1: j + w + 1]\n",
        "        for u in window:\n",
        "            # reset gradient về 0\n",
        "            optimizer.zero_grad()\n",
        "            # tính hàm mất mát\n",
        "            loss: Tensor = model(u, v)\n",
        "            # lan truyền ngược để tính gradient cho các parameter\n",
        "            loss.backward()\n",
        "            # tối ưu các parameter với gradient tính đc\n",
        "            optimizer.step()\n",
        "\n",
        "            # Ghi nhận lại hàm mất mát\n",
        "            running_loss += loss.item()\n",
        "            cnt += 1\n",
        "    return (running_loss, cnt)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T16:30:23.367623Z",
          "iopub.status.idle": "2024-05-27T16:30:23.368289Z",
          "shell.execute_reply.started": "2024-05-27T16:30:23.368031Z",
          "shell.execute_reply": "2024-05-27T16:30:23.368051Z"
        },
        "trusted": true,
        "id": "fiRfK2jZNgNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1D Embedding\n",
        "\n",
        "Embedding n-D bằng Deepwalk -> Embedding 1D bằng TSNE -> Sắp xếp lại thứ tự lá của Hierarchical Softmax\n"
      ],
      "metadata": {
        "id": "_5uajn_lNgNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ánh xạ từ đỉnh -> vị trí lá\n",
        "leaf_pos = list(range(V))\n",
        "\n",
        "# embedding sẽ được chuyển về 1 chiều bằng TSNE\n",
        "model = DeepwalkModel(V=V, emb_sz=EMBEDDING_SIZE, leaf_pos=leaf_pos).to(device)\n",
        "loss_records = []\n",
        "\n",
        "if WORKER_THREADS > 1:\n",
        "    model.share_memory()\n",
        "train_deepwalk(\n",
        "    model=model,\n",
        "    start_lr=START_LEARNING_RATE,\n",
        "    end_lr=(START_LEARNING_RATE + END_LEARNING_RATE) / 2.0,\n",
        "    vertices=list(vertices),\n",
        "    adj_lists=adj_lists,\n",
        "    loss_records=loss_records,\n",
        "    walk_len=WALK_LENGTH,\n",
        "    walks_per_vertex=PREPROCESS_WALKS_PER_VERTEX,\n",
        "    window_sz=WINDOW_SIZE,\n",
        "    worker_threads=WORKER_THREADS,\n",
        "    chunk_sz=CHUNK_SIZE,\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T16:30:23.370013Z",
          "iopub.status.idle": "2024-05-27T16:30:23.370537Z",
          "shell.execute_reply.started": "2024-05-27T16:30:23.370258Z",
          "shell.execute_reply": "2024-05-27T16:30:23.370278Z"
        },
        "trusted": true,
        "id": "dVq8bqZ7NgNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.tick_params(\"y\")\n",
        "plt.plot(loss_records)\n",
        "plt.title(\"Hàm mất mát theo epoch\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T16:30:23.37213Z",
          "iopub.status.idle": "2024-05-27T16:30:23.372487Z",
          "shell.execute_reply.started": "2024-05-27T16:30:23.372311Z",
          "shell.execute_reply": "2024-05-27T16:30:23.372326Z"
        },
        "trusted": true,
        "id": "GXCaM_7MNgNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chyển embedding về 1 chiều bằng TSNE rồi cập nhật lại vị trí lá cho Hierarchical Softmanx\n"
      ],
      "metadata": {
        "id": "z3G5FqqPNgNh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emb: Tensor = model.embedding_layer(tensor(list(g))).detach().cpu().numpy()\n",
        "df = pd.DataFrame(emb)\n",
        "df.to_csv(\"/kaggle/working/blog_prev_emb.csv\", header=False, index=False)\n",
        "# chuyển embedding về 1 chiều\n",
        "emb = TSNE(n_components=1, perplexity=PERPLEXITY).fit_transform(emb).flatten()\n",
        "\n",
        "\n",
        "# cập nhật thứ tự lá cho các đỉnh\n",
        "for pos, v in enumerate(sorted(vertices, key=lambda v: emb[v])):\n",
        "    leaf_pos[v] = pos\n",
        "\n",
        "print(vertices)\n",
        "print(leaf_pos)\n",
        "df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T16:30:23.374339Z",
          "iopub.status.idle": "2024-05-27T16:30:23.375208Z",
          "shell.execute_reply.started": "2024-05-27T16:30:23.374912Z",
          "shell.execute_reply": "2024-05-27T16:30:23.374934Z"
        },
        "trusted": true,
        "id": "lpxGWqaJNgNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### n-D Embedding\n"
      ],
      "metadata": {
        "id": "jN2vtibENgNh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = DeepwalkModel(V=V, emb_sz=EMBEDDING_SIZE, leaf_pos=leaf_pos).to(device)\n",
        "loss_records = []\n",
        "\n",
        "if WORKER_THREADS > 1:\n",
        "    model.share_memory()\n",
        "train_deepwalk(\n",
        "    model=model,\n",
        "    start_lr=START_LEARNING_RATE,\n",
        "    end_lr=END_LEARNING_RATE,\n",
        "    vertices=list(vertices),\n",
        "    adj_lists=adj_lists,\n",
        "    loss_records=loss_records,\n",
        "    walk_len=WALK_LENGTH,\n",
        "    walks_per_vertex=WALKS_PER_VERTEX,\n",
        "    window_sz=WINDOW_SIZE,\n",
        "    worker_threads=WORKER_THREADS,\n",
        "    chunk_sz=CHUNK_SIZE,\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T16:30:23.376445Z",
          "iopub.status.idle": "2024-05-27T16:30:23.376971Z",
          "shell.execute_reply.started": "2024-05-27T16:30:23.37668Z",
          "shell.execute_reply": "2024-05-27T16:30:23.3767Z"
        },
        "trusted": true,
        "id": "P8CE1orONgNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.tick_params(\"y\")\n",
        "plt.plot(loss_records)\n",
        "plt.title(\"Hàm mất mát theo epoch\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T16:30:23.378732Z",
          "iopub.status.idle": "2024-05-27T16:30:23.379175Z",
          "shell.execute_reply.started": "2024-05-27T16:30:23.378937Z",
          "shell.execute_reply": "2024-05-27T16:30:23.378957Z"
        },
        "trusted": true,
        "id": "eX5GuWtkNgNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb = model.embedding_layer(tensor(list(g))).detach().cpu().numpy()\n",
        "# emb = TSNE(n_components=2, perplexity=PERPLEXITY).fit_transform(emb)\n",
        "# pos = {v: v_emb for v, v_emb in enumerate(emb)}\n",
        "\n",
        "# nx.draw_networkx(g, pos)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T16:30:23.380472Z",
          "iopub.status.idle": "2024-05-27T16:30:23.380859Z",
          "shell.execute_reply.started": "2024-05-27T16:30:23.380656Z",
          "shell.execute_reply": "2024-05-27T16:30:23.380671Z"
        },
        "trusted": true,
        "id": "5jCosXOxNgNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(emb)\n",
        "df.to_csv(\"/kaggle/working/blog_emb.csv\", header=False, index=False)\n",
        "df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-27T16:30:23.382624Z",
          "iopub.status.idle": "2024-05-27T16:30:23.383235Z",
          "shell.execute_reply.started": "2024-05-27T16:30:23.383006Z",
          "shell.execute_reply": "2024-05-27T16:30:23.383029Z"
        },
        "trusted": true,
        "id": "G-JDCYliNgNi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}